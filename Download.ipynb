{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 1950 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1950\n",
      "Data for 1951 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1951\n",
      "Data for 1952 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1952\n",
      "Data for 1953 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1953\n",
      "Data for 1954 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1954\n",
      "Data for 1955 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1955\n",
      "Data for 1956 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1956\n",
      "Data for 1957 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1957\n",
      "Data for 1958 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1958\n",
      "Data for 1959 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1959\n",
      "Data for 1960 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1960\n",
      "Data for 1961 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1961\n",
      "Data for 1962 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1962\n",
      "Data for 1963 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1963\n",
      "Data for 1964 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1964\n",
      "Data for 1965 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1965\n",
      "Data for 1966 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1966\n",
      "Data for 1967 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1967\n",
      "Data for 1968 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1968\n",
      "Data for 1969 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1969\n",
      "Data for 1970 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1970\n",
      "Data for 1971 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1971\n",
      "Data for 1972 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1972\n",
      "Data for 1973 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1973\n",
      "Data for 1974 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1974\n",
      "Data for 1975 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1975\n",
      "Data for 1976 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1976\n",
      "Data for 1977 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1977\n",
      "Data for 1978 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1978\n",
      "Data for 1979 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1979\n",
      "Data for 1980 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1980\n",
      "Data for 1981 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1981\n",
      "Data for 1982 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1982\n",
      "Data for 1983 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1983\n",
      "Data for 1984 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1984\n",
      "Data for 1985 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1985\n",
      "Data for 1986 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1986\n",
      "Data for 1987 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1987\n",
      "Data for 1988 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1988\n",
      "Data for 1989 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1989\n",
      "Data for 1990 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1990\n",
      "Data for 1991 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1991\n",
      "Data for 1992 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1992\n",
      "Data for 1993 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1993\n",
      "Data for 1994 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1994\n",
      "Data for 1995 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1995\n",
      "Data for 1996 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1996\n",
      "Data for 1997 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1997\n",
      "Data for 1998 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1998\n",
      "Data for 1999 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/1999\n",
      "Data for 2000 downloaded and extracted to /users/yorkmacbook023/ETL_Assignment/Testing/2000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sqlalchemy as sql\n",
    "\n",
    "start_year = 1950\n",
    "end_year = 2000\n",
    "\n",
    "# Iterate over the range of years\n",
    "for year in range(start_year, end_year + 1):\n",
    "    url = f\"https://www.ncei.noaa.gov/data/global-summary-of-the-day/archive/{year}.tar.gz\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    \n",
    "    # Specify the output path for each year\n",
    "    output_path = f\"/users/yorkmacbook023/ETL_Assignment/Testing/{year}\"\n",
    "    \n",
    "    # Extract the tar.gz file\n",
    "    with tarfile.open(fileobj=response.raw, mode=\"r|gz\") as file:\n",
    "        file.extractall(path=output_path)\n",
    "\n",
    "    print(f\"Data for {year} downloaded and extracted to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          DATE  MEAN_TEMP  MEDIAN_TEMP    VAR_TEMP  TOTAL_PRCP  MEAN_PRCP  \\\n",
      "0   1950-01-31  37.728782         38.9  422.453940      119.92   0.006645   \n",
      "1   1950-02-28  39.594828         39.8  269.712350       79.53   0.004839   \n",
      "2   1950-03-31  42.962140         42.7  238.036702      111.07   0.006146   \n",
      "3   1950-04-30  51.908767         51.6  169.314507       88.57   0.005078   \n",
      "4   1950-05-31  62.570687         62.7  130.067132      100.64   0.005619   \n",
      "..         ...        ...          ...         ...         ...        ...   \n",
      "607 2000-08-31  74.472012         74.3   81.534235     1879.42   0.051388   \n",
      "608 2000-09-30  67.196867         67.3  134.149328     2468.62   0.069812   \n",
      "609 2000-10-31  57.564186         57.6  130.491212     1763.95   0.048162   \n",
      "610 2000-11-30  42.655549         42.6  216.265050     1973.34   0.055992   \n",
      "611 2000-12-31  31.289599         30.9  313.108558     1200.03   0.033197   \n",
      "\n",
      "     MEDIAN_PRCP  VAR_PRCP  MIN_PRCP  MAX_PRCP   MIN    MAX  \n",
      "0            0.0  0.004800       0.0      2.68 -50.1   93.4  \n",
      "1            0.0  0.002962       0.0      1.65 -38.9   92.3  \n",
      "2            0.0  0.004164       0.0      2.09 -29.0  105.1  \n",
      "3            0.0  0.003135       0.0      2.44 -13.0  105.1  \n",
      "4            0.0  0.004967       0.0      4.53  12.0  108.0  \n",
      "..           ...       ...       ...       ...   ...    ...  \n",
      "607          0.0  0.047307       0.0      7.16  26.6  119.5  \n",
      "608          0.0  0.094526       0.0      9.23  10.4  127.9  \n",
      "609          0.0  0.053222       0.0     12.48 -14.8  104.5  \n",
      "610          0.0  0.056238       0.0      6.74 -32.8   93.2  \n",
      "611          0.0  0.030057       0.0     13.90 -49.0   91.8  \n",
      "\n",
      "[612 rows x 12 columns]\n",
      "CSV file saved at: /Users/yorkmacbook023/classDay1/Kanwalpreet-Kaur-weather-ETL/monthly_aggregated_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sql\n",
    "import glob\n",
    "\n",
    "# Define the range of years\n",
    "start_year = 1950\n",
    "end_year = 2000\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterate through each year in the range\n",
    "for year in range(start_year, end_year + 1):\n",
    "    # Construct the path for CSV files for each year\n",
    "    csv_files = glob.glob(f\"/Users/yorkmacbook023/ETL_Assignment/Testing/{year}/*.csv\")\n",
    "\n",
    "    # Initialize an empty list to store DataFrames for the current year\n",
    "    dfs_year = []\n",
    "\n",
    "    # Iterate through each CSV file for the current year starting with '7' or '69'\n",
    "    for csv_file in csv_files:\n",
    "        # Include files starting with '7', '69', and '99', but exclude '71'\n",
    "        if csv_file.split(\"/\")[-1].startswith(('7', '69', '99')) and not csv_file.split(\"/\")[-1].startswith(('71','76')):\n",
    "            df = pd.read_csv(csv_file)\n",
    "            #df = df[df['NAME'].astype(str).str.contains('AK|HI', case=False, na=False)]\n",
    "            df = df[df['NAME'].astype(str).str.contains('US', case=False, na=False) & ~df['NAME'].astype(str).str.contains('AK|HI', case=False, na=False)]\n",
    "\n",
    "            # Replace values of 99.99 in the 'PRCP' column with 0\n",
    "            df['PRCP'].replace(99.99, 0, inplace=True)\n",
    "\n",
    "            # Replace values of 9999.9 in 'MAX', 'MIN', 'TEMP' columns with NaN\n",
    "            df[['MAX', 'MIN', 'TEMP']] = df[['MAX', 'MIN', 'TEMP']].replace(9999.9, float('nan'))\n",
    "            df.dropna(subset=['TEMP', 'MIN', 'MAX', 'PRCP'], inplace=True)\n",
    "\n",
    "            dfs_year.append(df)\n",
    "            # Delete the CSV file after reading and processing\n",
    "            os.remove(csv_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Concatenate all DataFrames for the current year\n",
    "    combined_data_year = pd.concat(dfs_year, ignore_index=True)\n",
    "\n",
    "    # Convert the 'DATE' column to datetime for easier manipulation\n",
    "    combined_data_year['DATE'] = pd.to_datetime(combined_data_year['DATE'], format='%Y-%m-%d')\n",
    "\n",
    "    # Append the DataFrame for the current year to the list\n",
    "    dfs.append(combined_data_year)\n",
    "\n",
    "# Concatenate all DataFrames for the entire range of years\n",
    "combined_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Aggregate the data on a monthly basis, including additional metrics\n",
    "monthly_aggregated_data = combined_data.groupby(pd.Grouper(key='DATE', freq='M')).agg({\n",
    "    'TEMP': ['mean', 'median', 'var'],\n",
    "    'PRCP': ['sum', 'mean', 'median', 'var', 'min', 'max'],\n",
    "    'MIN': 'min',\n",
    "    'MAX': 'max'\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Rename columns for clarity\n",
    "monthly_aggregated_data.columns = [\n",
    "    'DATE', 'MEAN_TEMP', 'MEDIAN_TEMP', 'VAR_TEMP', 'TOTAL_PRCP', 'MEAN_PRCP', 'MEDIAN_PRCP', 'VAR_PRCP', 'MIN_PRCP', 'MAX_PRCP', 'MIN', 'MAX'\n",
    "]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(monthly_aggregated_data)\n",
    "csv_output_path = \"/Users/yorkmacbook023/classDay1/Kanwalpreet-Kaur-weather-ETL/monthly_aggregated_data.csv\"\n",
    "monthly_aggregated_data.to_csv(csv_output_path, index=False)\n",
    "print(f\"CSV file saved at: {csv_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'Monthly_weather_data' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/yorkmacbook023/classDay1/Kanwalpreet-Kaur-weather-ETL/monthly_aggregated_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m e\u001b[38;5;241m.\u001b[39mbegin() \u001b[38;5;28;01mas\u001b[39;00m connection:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMonthly_weather_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/generic.py:3008\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2814\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2815\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3004\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   3005\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[0;32m-> 3008\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3013\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3014\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3019\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/sql.py:788\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    785\u001b[0m     )\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema\u001b[38;5;241m=\u001b[39mschema, need_transaction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/sql.py:1948\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;124;03m    Any additional kwargs are passed to the engine.\u001b[39;00m\n\u001b[1;32m   1945\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m sql_engine \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m-> 1948\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1954\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1956\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1958\u001b[0m total_inserted \u001b[38;5;241m=\u001b[39m sql_engine\u001b[38;5;241m.\u001b[39minsert_records(\n\u001b[1;32m   1959\u001b[0m     table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[1;32m   1960\u001b[0m     con\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1967\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[1;32m   1968\u001b[0m )\n\u001b[1;32m   1970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_case_sensitive(name\u001b[38;5;241m=\u001b[39mname, schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/sql.py:1852\u001b[0m, in \u001b[0;36mSQLDatabase.prep_table\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, dtype)\u001b[0m\n\u001b[1;32m   1840\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe type of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a SQLAlchemy type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1842\u001b[0m table \u001b[38;5;241m=\u001b[39m SQLTable(\n\u001b[1;32m   1843\u001b[0m     name,\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1850\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1851\u001b[0m )\n\u001b[0;32m-> 1852\u001b[0m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/sql.py:927\u001b[0m, in \u001b[0;36mSQLTable.create\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfail\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 927\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mif_exists \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    929\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpd_sql\u001b[38;5;241m.\u001b[39mdrop_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema)\n",
      "\u001b[0;31mValueError\u001b[0m: Table 'Monthly_weather_data' already exists."
     ]
    }
   ],
   "source": [
    "e = sql.create_engine(\n",
    "        'postgresql://postgres:password@localhost:5432/postgres')\n",
    "\n",
    "df = pd.read_csv(\"/Users/yorkmacbook023/classDay1/Kanwalpreet-Kaur-weather-ETL/monthly_aggregated_data.csv\")\n",
    "with e.begin() as connection:\n",
    "    df.to_sql(\"Monthly_weather_data\", con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
